{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Load and Preprocess Data](#toc1_1_)    \n",
    "- [Helper Functions](#toc1_2_)    \n",
    "- [Hyperparameter Tuning](#toc1_3_)    \n",
    "- [Model Training and Evaluation](#toc1_4_)    \n",
    "- [Run All Models Across All Pairs](#toc1_5_)    \n",
    "- [Results Analysis](#toc1_6_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darien/miniforge3/envs/tradingScratch310/lib/python3.10/site-packages/dask/dataframe/__init__.py:31: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "<ipython-input-1-1130c5f83de4>:25: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner import HyperModel, HyperParameters, RandomSearch\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import glob\n",
    "import pickle\n",
    "import logging\n",
    "from tabulate import tabulate\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from lightgbm import LGBMRegressor\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Bidirectional, Dropout\n",
    "from keras.callbacks import EarlyStopping, History, ModelCheckpoint, CSVLogger, TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "from kerastuner import HyperModel, HyperParameters, RandomSearch\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# plt.style.use('./../.templates/custom_onedark.mplstyle')\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Load and Preprocess Data](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurable parameters\n",
    "DATA_DIR = '../data/'\n",
    "PRICE_HISTORY_DIR = os.path.join(DATA_DIR, 'price_history/')\n",
    "SENTIMENT_DIR = os.path.join(DATA_DIR, 'sentiments/')\n",
    "TI_DIR = os.path.join(DATA_DIR, 'technical_indicators/')\n",
    "\n",
    "MA_HIGH = 45\n",
    "MA_LOW = 5\n",
    "SPREAD_WINDOW = None\n",
    "LOOK_BACK = 3\n",
    "ADD_SENTIMENT_MA = True\n",
    "\n",
    "# Load ticker pairs\n",
    "tickers_list = [file.split('/')[-1].strip('.csv') for file in glob.glob(PRICE_HISTORY_DIR + '*.csv')]\n",
    "pairs_df = pd.read_csv(os.path.join(DATA_DIR, 'ranked_pairs_snp.csv'))\n",
    "pairs = pairs_df[['ticker_0', 'ticker_1']].values\n",
    "\n",
    "class TickerData:\n",
    "    def __init__(self, ticker):\n",
    "        self.ticker = ticker\n",
    "        self.history = pd.read_csv(os.path.join(PRICE_HISTORY_DIR, f'{ticker}.csv'), index_col='Date', date_format='%Y-%m-%d')\n",
    "        self.sentiment = pd.read_csv(os.path.join(SENTIMENT_DIR, f'{ticker}.csv'), index_col='Date', date_format='%Y-%m-%d')\n",
    "        self.ti = pd.read_csv(os.path.join(TI_DIR, f'{ticker}.csv'), index_col='Date', date_format='%Y-%m-%d')\n",
    "\n",
    "logger.info(\"Loading ticker data...\")\n",
    "data = {ticker: TickerData(ticker) for ticker in tqdm(tickers_list, desc=\"Loading ticker data\")}\n",
    "logger.info(f\"Loaded data for {len(data)} tickers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Helper Functions](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_moving_averages(df, moving_averages, columns):\n",
    "    df = df.copy()\n",
    "    for ma in moving_averages:\n",
    "        for col in columns:\n",
    "            new_col = f'{col}_ma{ma}'\n",
    "            df[new_col] = df[col].rolling(window=ma).mean()\n",
    "    return df.fillna(method='ffill')\n",
    "\n",
    "def get_spread(S1_train, S2_train, S1_full, S2_full):\n",
    "    s1_ols = sm.add_constant(S1_train)\n",
    "    spread_model = sm.OLS(S2_train, s1_ols).fit()\n",
    "    beta = spread_model.params[S1_train.name]\n",
    "    \n",
    "    # Calculate spread for full dataset using beta from training data\n",
    "    spread_full = S2_full - beta * S1_full\n",
    "    return spread_full, beta\n",
    "\n",
    "def create_dataset(data, look_back, target_col=\"zscore_spread\", split_sizes=[0.4, 0.1, 0.5], drop_cols=None):\n",
    "    data = data.copy().dropna()\n",
    "    \n",
    "    train_size = int(len(data) * split_sizes[0])\n",
    "    val_size = int(len(data) * split_sizes[1])\n",
    "    \n",
    "    train_data = data.iloc[:train_size]\n",
    "    val_data = data.iloc[train_size:train_size+val_size]\n",
    "    test_data = data.iloc[train_size+val_size:]\n",
    "    \n",
    "    logger.info(f\"Train size: {train_size}, Val size: {val_size}, Test size: {len(data) - train_size - val_size}\")\n",
    "    \n",
    "    # Calculate spread using only training data\n",
    "    spread_full, beta = get_spread(\n",
    "        train_data['Adj Close_S1'], \n",
    "        train_data['Adj Close_S2'],\n",
    "        data['Adj Close_S1'],\n",
    "        data['Adj Close_S2']\n",
    "    )\n",
    "    \n",
    "    data['spread'] = spread_full\n",
    "    \n",
    "    # Calculate z-score\n",
    "    ma_high = data['spread'].rolling(window=MA_HIGH).mean()\n",
    "    ma_low = data['spread'].rolling(window=MA_LOW).mean()\n",
    "    std_high = data['spread'].rolling(window=MA_HIGH).std()\n",
    "    \n",
    "    data['zscore_spread'] = (ma_low - ma_high) / std_high\n",
    "    \n",
    "    y = data[target_col]\n",
    "    y_shifted = y.shift(-look_back)\n",
    "    data[\"target\"] = y_shifted\n",
    "    \n",
    "    if drop_cols:\n",
    "        data = data.drop(drop_cols, axis=1)\n",
    "    \n",
    "    data = data.dropna()\n",
    "    \n",
    "    train_data = data.iloc[:train_size]\n",
    "    val_data = data.iloc[train_size:train_size+val_size]\n",
    "    test_data = data.iloc[train_size+val_size:]\n",
    "    \n",
    "    logger.info(f\"Final dataset shapes - Train: {train_data.shape}, Val: {val_data.shape}, Test: {test_data.shape}\")\n",
    "    \n",
    "    return train_data, val_data, test_data, beta\n",
    "\n",
    "def prepare_dataset(train_data, val_data, test_data):\n",
    "    X_train, y_train = train_data.drop(columns=[\"target\"]), train_data[\"target\"]\n",
    "    X_val, y_val = val_data.drop(columns=[\"target\"]), val_data[\"target\"]\n",
    "    X_test, y_test = test_data.drop(columns=[\"target\"]), test_data[\"target\"]\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"r2\": r2_score(y_true, y_pred),\n",
    "        \"mae\": mean_absolute_error(y_true, y_pred),\n",
    "        \"mse\": mean_squared_error(y_true, y_pred),\n",
    "        \"rmse\": np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "    }\n",
    "\n",
    "def preprocess_pair_data(pair):\n",
    "    pair_sentiment_df = pd.merge(data[pair[0]].sentiment, data[pair[1]].sentiment, left_index=True, right_index=True, suffixes=(\"_S1\", \"_S2\"))\n",
    "    if ADD_SENTIMENT_MA:\n",
    "        pair_sentiment_df = add_moving_averages(pair_sentiment_df, [5, 10, 20, 40, 80], columns=pair_sentiment_df.columns)\n",
    "    \n",
    "    pair_ti_df = pd.merge(data[pair[0]].ti, data[pair[1]].ti, left_index=True, right_index=True, suffixes=(\"_S1\", \"_S2\"))\n",
    "    pair_df = pd.merge(pair_ti_df, pair_sentiment_df, left_index=True, right_index=True, how=\"left\")\n",
    "    \n",
    "    pair_df = pair_df[pair_df.index < '2024-01-01']\n",
    "    \n",
    "    logger.info(f\"Preprocessed pair data shape: {pair_df.shape}\")\n",
    "    \n",
    "    return pair_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[Hyperparameter Tuning](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape):\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = Sequential()\n",
    "        \n",
    "        for i in range(hp.Int('num_lstm_layers', 1, 3)):\n",
    "            return_sequences = i < hp.Int('num_lstm_layers', 1, 3) - 1\n",
    "            units = hp.Int(f'lstm_{i}_units', 50, 200, step=50)\n",
    "            model.add(LSTM(units, return_sequences=return_sequences, input_shape=self.input_shape))\n",
    "            model.add(Dropout(hp.Float(f'lstm_{i}_dropout', 0.1, 0.5, step=0.1)))\n",
    "        \n",
    "        for i in range(hp.Int('num_dense_layers', 1, 2)):\n",
    "            units = hp.Int(f'dense_{i}_units', 50, 200, step=50)\n",
    "            model.add(Dense(units, activation='relu'))\n",
    "        \n",
    "        model.add(Dense(1, activation='linear'))\n",
    "        \n",
    "        optimizer = Adam(learning_rate=hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4]))\n",
    "        model.compile(optimizer=optimizer, loss='mae', metrics=['mae', 'mse'])\n",
    "        \n",
    "        return model\n",
    "\n",
    "def perform_hyperparameter_tuning(X_train_lstm, y_train):\n",
    "    logger.info(\"Starting hyperparameter tuning...\")\n",
    "    hypermodel = LSTMHyperModel(input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2]))\n",
    "    \n",
    "    log_dir = os.path.join(\"logs\", \"hyperparameter_tuning\", datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    \n",
    "    tuner = RandomSearch(\n",
    "        hypermodel,\n",
    "        objective='val_loss',\n",
    "        max_trials=100,\n",
    "        executions_per_trial=3,\n",
    "        directory='tuner_results',\n",
    "        project_name='lstm_tuner'\n",
    "    )\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=4)\n",
    "    \n",
    "    tuner.search(X_train_lstm, y_train, epochs=50, validation_split=0.2, \n",
    "                 callbacks=[early_stopping, tensorboard_callback],\n",
    "                 verbose=1)\n",
    "    \n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "    best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    \n",
    "    logger.info(f\"Best hyperparameters: {best_hyperparameters.values}\")\n",
    "    \n",
    "    return best_model, best_hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_4_'></a>[Model Training and Evaluation](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, X_train, y_train, X_test, y_test, model_name):\n",
    "    logger.info(f\"Training {model_name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    metrics = calculate_metrics(y_test, y_pred)\n",
    "    \n",
    "    logger.info(f\"{model_name} metrics: {metrics}\")\n",
    "    \n",
    "    return {\n",
    "        'metrics': metrics,\n",
    "        'y_pred': y_pred,\n",
    "    }\n",
    "\n",
    "def train_and_evaluate_lstm(model, X_train, y_train, X_val, y_val, X_test, y_test, model_name, epochs=100, batch_size=16):\n",
    "    logger.info(f\"Training {model_name}...\")\n",
    "    log_dir = os.path.join(\"logs\", model_name, datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=6)\n",
    "    history = History()\n",
    "    csv_logger = CSVLogger(f'{model_name.lower()}_training.log')\n",
    "    model_checkpoint = ModelCheckpoint(f'best_model_{model_name.lower()}.keras', monitor='val_loss', mode='min')\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epochs,\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=1,\n",
    "        callbacks=[early_stopping, history, csv_logger, model_checkpoint, tensorboard_callback],\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    metrics = calculate_metrics(y_test, y_pred.flatten())\n",
    "    \n",
    "    logger.info(f\"{model_name} metrics: {metrics}\")\n",
    "    \n",
    "    return {\n",
    "        'metrics': metrics,\n",
    "        'y_pred': y_pred,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_5_'></a>[Run All Models Across All Pairs](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models_on_pair(pair):\n",
    "    logger.info(f\"Processing pair: {pair}\")\n",
    "    pair_df = preprocess_pair_data(pair)\n",
    "    train_data, val_data, test_data, beta = create_dataset(pair_df, look_back=LOOK_BACK, target_col=\"zscore_spread\")\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = prepare_dataset(train_data, val_data, test_data)\n",
    "    \n",
    "    model_results = {}\n",
    "    \n",
    "    # Traditional ML models\n",
    "    base_models = [\n",
    "        LinearRegression(),\n",
    "        GradientBoostingRegressor(random_state=42),\n",
    "        RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "        LGBMRegressor(random_state=42, verbose=-1),\n",
    "    ]\n",
    "    \n",
    "    for model in tqdm(base_models, desc=\"Training traditional ML models\"):\n",
    "        model_name = model.__class__.__name__\n",
    "        model_results[model_name] = train_and_evaluate_model(model, X_train, y_train, X_test, y_test, model_name)\n",
    "    \n",
    "    # Prepare data for LSTM models\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    X_train_lstm = X_train_scaled.reshape((X_train_scaled.shape[0], LOOK_BACK, -1))\n",
    "    X_val_lstm = X_val_scaled.reshape((X_val_scaled.shape[0], LOOK_BACK, -1))\n",
    "    X_test_lstm = X_test_scaled.reshape((X_test_scaled.shape[0], LOOK_BACK, -1))\n",
    "    \n",
    "    # LSTM models\n",
    "    lstm_models = {\n",
    "        'Vanilla LSTM': Sequential([\n",
    "            LSTM(50, return_sequences=True,\n",
    "            'Vanilla LSTM': Sequential([\n",
    "            LSTM(50, return_sequences=True, input_shape=(LOOK_BACK, X_train_lstm.shape[2])),\n",
    "            LSTM(50),\n",
    "            Dense(1)\n",
    "        ]),\n",
    "        'LSTM': Sequential([\n",
    "            LSTM(150, return_sequences=True, input_shape=(LOOK_BACK, X_train_lstm.shape[2])),\n",
    "            Dropout(0.4),\n",
    "            LSTM(150),\n",
    "            Dropout(0.3),\n",
    "            Dense(200, activation='relu'),\n",
    "            Dense(1, activation='linear')\n",
    "        ]),\n",
    "        'BiLSTM': Sequential([\n",
    "            Bidirectional(LSTM(100, return_sequences=True), input_shape=(LOOK_BACK, X_train_lstm.shape[2])),\n",
    "            Dropout(0.2),\n",
    "            Bidirectional(LSTM(100, return_sequences=True)),\n",
    "            Dropout(0.2),\n",
    "            Bidirectional(LSTM(50)),\n",
    "            Dropout(0.2),\n",
    "            Dense(50, activation='relu'),\n",
    "            Dense(1)\n",
    "        ])\n",
    "    }\n",
    "    \n",
    "    for model_name, model in tqdm(lstm_models.items(), desc=\"Training LSTM models\"):\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='mae', metrics=['mae', 'mse'])\n",
    "        model_results[model_name] = train_and_evaluate_lstm(\n",
    "            model, X_train_lstm, y_train, X_val_lstm, y_val, X_test_lstm, y_test, model_name\n",
    "        )\n",
    "        model_results[model_name]['X_test_og'] = X_test\n",
    "    \n",
    "    logger.info(f\"Completed processing pair: {pair}\")\n",
    "    return model_results, beta\n",
    "\n",
    "# Run for all pairs\n",
    "ticker_results = {}\n",
    "\n",
    "for pair in tqdm(pairs, desc=\"Processing pairs\"):\n",
    "    logger.info(f\"Starting processing for pair: {pair}\")\n",
    "    try:\n",
    "        ticker_results[tuple(pair)], beta = run_models_on_pair(pair)\n",
    "        ticker_results[tuple(pair)]['beta'] = beta\n",
    "        logger.info(f\"Successfully processed pair: {pair}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing pair {pair}: {str(e)}\")\n",
    "\n",
    "# Save results\n",
    "logger.info(\"Saving results...\")\n",
    "with open('all_models_all_tickers.pkl', 'wb') as f:\n",
    "    pickle.dump(ticker_results, f)\n",
    "\n",
    "logger.info(\"All models have been trained and evaluated. Results saved in 'all_models_all_tickers.pkl'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_6_'></a>[Results Analysis](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models_on_pair(pair):\n",
    "    logger.info(f\"Processing pair: {pair}\")\n",
    "    pair_df = preprocess_pair_data(pair)\n",
    "    train_data, val_data, test_data, beta = create_dataset(pair_df, look_back=LOOK_BACK, target_col=\"zscore_spread\")\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = prepare_dataset(train_data, val_data, test_data)\n",
    "    \n",
    "    model_results = {}\n",
    "    \n",
    "    # Traditional ML models\n",
    "    base_models = [\n",
    "        LinearRegression(),\n",
    "        GradientBoostingRegressor(random_state=42),\n",
    "        RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "        LGBMRegressor(random_state=42, verbose=-1),\n",
    "    ]\n",
    "    \n",
    "    for model in tqdm(base_models, desc=\"Training traditional ML models\"):\n",
    "        model_name = model.__class__.__name__\n",
    "        model_results[model_name] = train_and_evaluate_model(model, X_train, y_train, X_test, y_test, model_name)\n",
    "    \n",
    "    # Prepare data for LSTM models\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    X_train_lstm = X_train_scaled.reshape((X_train_scaled.shape[0], LOOK_BACK, -1))\n",
    "    X_val_lstm = X_val_scaled.reshape((X_val_scaled.shape[0], LOOK_BACK, -1))\n",
    "    X_test_lstm = X_test_scaled.reshape((X_test_scaled.shape[0], LOOK_BACK, -1))\n",
    "\n",
    "    # LSTM models\n",
    "    lstm_models = {\n",
    "        'Vanilla LSTM': Sequential([\n",
    "            LSTM(50, return_sequences=True, input_shape=(LOOK_BACK, X_train_lstm.shape[2])),\n",
    "            LSTM(50),\n",
    "            Dense(1)\n",
    "        ]),\n",
    "        'LSTM': Sequential([\n",
    "            LSTM(150, return_sequences=True, input_shape=(LOOK_BACK, X_train_lstm.shape[2])),\n",
    "            Dropout(0.4),\n",
    "            LSTM(150),\n",
    "            Dropout(0.3),\n",
    "            Dense(200, activation='relu'),\n",
    "            Dense(1, activation='linear')\n",
    "        ]),\n",
    "        'BiLSTM': Sequential([\n",
    "            Bidirectional(LSTM(100, return_sequences=True), input_shape=(LOOK_BACK, X_train_lstm.shape[2])),\n",
    "            Dropout(0.2),\n",
    "            Bidirectional(LSTM(100, return_sequences=True)),\n",
    "            Dropout(0.2),\n",
    "            Bidirectional(LSTM(50)),\n",
    "            Dropout(0.2),\n",
    "            Dense(50, activation='relu'),\n",
    "            Dense(1)\n",
    "        ])\n",
    "    }\n",
    "    \n",
    "    for model_name, model in tqdm(lstm_models.items(), desc=\"Training LSTM models\"):\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='mae', metrics=['mae', 'mse'])\n",
    "        model_results[model_name] = train_and_evaluate_lstm(\n",
    "            model, X_train_lstm, y_train, X_val_lstm, y_val, X_test_lstm, y_test, model_name\n",
    "        )\n",
    "        model_results[model_name]['X_test_og'] = X_test\n",
    "    \n",
    "    logger.info(f\"Completed processing pair: {pair}\")\n",
    "    return model_results, beta\n",
    "\n",
    "# Run for all pairs\n",
    "ticker_results = {}\n",
    "\n",
    "for pair in tqdm(pairs, desc=\"Processing pairs\"):\n",
    "    logger.info(f\"Starting processing for pair: {pair}\")\n",
    "    try:\n",
    "        ticker_results[tuple(pair)], beta = run_models_on_pair(pair)\n",
    "        ticker_results[tuple(pair)]['beta'] = beta\n",
    "        logger.info(f\"Successfully processed pair: {pair}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing pair {pair}: {str(e)}\")\n",
    "\n",
    "# Save results\n",
    "logger.info(\"Saving results...\")\n",
    "with open('all_models_all_tickers.pkl', 'wb') as f:\n",
    "    pickle.dump(ticker_results, f)\n",
    "\n",
    "logger.info(\"All models have been trained and evaluated. Results saved in 'all_models_all_tickers.pkl'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
